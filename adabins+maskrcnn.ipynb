{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "adabins+maskrcnn",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAW-a_thYosb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7316e07d-caf8-4e69-9b76-5d76665bfa83"
      },
      "source": [
        "# install dependencies\n",
        "!pip uninstall tensorflow \\\n",
        "  tensorflow-gpu\n",
        "!pip install keras==2.0.8 \\\n",
        "  tensorflow-gpu==1.14.0 \\\n",
        "  scikit-image==0.14.2 \\\n",
        "  imgaug==0.2.5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.4.1:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-2.4.1.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.4.1\n",
            "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n",
            "Collecting keras==2.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/3f/d117d6e48b19fb9589369f4bdbe883aa88943f8bb4a850559ea5c546fefb/Keras-2.0.8-py2.py3-none-any.whl (276kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 5.5MB/s \n",
            "\u001b[?25hCollecting tensorflow-gpu==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/67/559ca8408431c37ad3a17e859c8c291ea82f092354074baef482b98ffb7b/tensorflow_gpu-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (377.1MB)\n",
            "\u001b[K     |████████████████████████████████| 377.1MB 46kB/s \n",
            "\u001b[?25hCollecting scikit-image==0.14.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/66/a7f7649e5abf9cf1a908134fe6b52f8c5bb4e4059e47dd497bd173a951c6/scikit_image-0.14.2-cp37-cp37m-manylinux1_x86_64.whl (25.3MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3MB 127kB/s \n",
            "\u001b[?25hCollecting imgaug==0.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/60/a06a48d85a7e9062f5870347a3e3e953da30b37928d43b380c949bca458a/imgaug-0.2.5.tar.gz (562kB)\n",
            "\u001b[K     |████████████████████████████████| 563kB 37.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.0.8) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.0.8) (1.19.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.0.8) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (3.12.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.36.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.2.0)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.1.2)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 35.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.3.3)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 37.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.32.0)\n",
            "Requirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.2) (1.3.0)\n",
            "Requirement already satisfied: dask[array]>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.2) (2.12.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.2) (3.2.2)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.2) (2.5.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.2) (1.1.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.2) (7.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14.0) (56.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: toolz>=0.7.3; extra == \"array\" in /usr/local/lib/python3.7/dist-packages (from dask[array]>=1.0.0->scikit-image==0.14.2) (0.11.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-image==0.14.2) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-image==0.14.2) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-image==0.14.2) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-image==0.14.2) (2.4.7)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=1.8->scikit-image==0.14.2) (4.4.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.7.4.3)\n",
            "Building wheels for collected packages: imgaug\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.5-cp37-none-any.whl size=561439 sha256=ff7f4353616574670415c1be573339de370812f5d1bddc8599ecf4e1625bdce3\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/48/c8/ca3345e8582a078de94243996e148377ef66fdb845557bae0b\n",
            "Successfully built imgaug\n",
            "\u001b[31mERROR: fancyimpute 0.4.3 requires tensorflow, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: textgenrnn 1.4.1 has requirement keras>=2.1.5, but you'll have keras 2.0.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras, keras-applications, tensorflow-estimator, tensorboard, tensorflow-gpu, scikit-image, imgaug\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: scikit-image 0.16.2\n",
            "    Uninstalling scikit-image-0.16.2:\n",
            "      Successfully uninstalled scikit-image-0.16.2\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "Successfully installed imgaug-0.2.5 keras-2.0.8 keras-applications-1.0.8 scikit-image-0.14.2 tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD0-V3-zXW6_",
        "outputId": "e923197c-4baf-4564-d5d7-e3827746d89c"
      },
      "source": [
        "# setup depth network - adabins and load model\n",
        "\n",
        "%cd /content/drive/MyDrive/AdaBins\n",
        "\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "import model_io\n",
        "import utils\n",
        "from models import UnetAdaptiveBins\n",
        "\n",
        "\n",
        "def _is_pil_image(img):\n",
        "    return isinstance(img, Image.Image)\n",
        "\n",
        "\n",
        "def _is_numpy_image(img):\n",
        "    return isinstance(img, np.ndarray) and (img.ndim in {2, 3})\n",
        "\n",
        "\n",
        "class ToTensor(object):\n",
        "    def __init__(self):\n",
        "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "    def __call__(self, image, target_size=(640, 480)):\n",
        "        # image = image.resize(target_size)\n",
        "        image = self.to_tensor(image)\n",
        "        image = self.normalize(image)\n",
        "        return image\n",
        "\n",
        "    def to_tensor(self, pic):\n",
        "        if not (_is_pil_image(pic) or _is_numpy_image(pic)):\n",
        "            raise TypeError(\n",
        "                'pic should be PIL Image or ndarray. Got {}'.format(type(pic)))\n",
        "\n",
        "        if isinstance(pic, np.ndarray):\n",
        "            img = torch.from_numpy(pic.transpose((2, 0, 1)))\n",
        "            return img\n",
        "\n",
        "        # handle PIL Image\n",
        "        if pic.mode == 'I':\n",
        "            img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
        "        elif pic.mode == 'I;16':\n",
        "            img = torch.from_numpy(np.array(pic, np.int16, copy=False))\n",
        "        else:\n",
        "            img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
        "        # PIL image mode: 1, L, P, I, F, RGB, YCbCr, RGBA, CMYK\n",
        "        if pic.mode == 'YCbCr':\n",
        "            nchannel = 3\n",
        "        elif pic.mode == 'I;16':\n",
        "            nchannel = 1\n",
        "        else:\n",
        "            nchannel = len(pic.mode)\n",
        "        img = img.view(pic.size[1], pic.size[0], nchannel)\n",
        "\n",
        "        img = img.transpose(0, 1).transpose(0, 2).contiguous()\n",
        "        if isinstance(img, torch.ByteTensor):\n",
        "            return img.float()\n",
        "        else:\n",
        "            return img\n",
        "\n",
        "\n",
        "class InferenceHelper:\n",
        "    def __init__(self, dataset='nyu', device='cuda'):\n",
        "        self.toTensor = ToTensor()\n",
        "        self.device = device\n",
        "        if dataset == 'nyu':\n",
        "            self.min_depth = 1e-3\n",
        "            self.max_depth = 10\n",
        "            self.saving_factor = 1000  # used to save in 16 bit\n",
        "            model = UnetAdaptiveBins.build(n_bins=256, min_val=self.min_depth, max_val=self.max_depth)\n",
        "            pretrained_path = \"./pretrained/AdaBins_nyu.pt\"\n",
        "        elif dataset == 'kitti':\n",
        "            self.min_depth = 1e-3\n",
        "            self.max_depth = 80\n",
        "            self.saving_factor = 256\n",
        "            model = UnetAdaptiveBins.build(n_bins=256, min_val=self.min_depth, max_val=self.max_depth)\n",
        "            pretrained_path = \"./pretrained/AdaBins_kitti.pt\"\n",
        "        else:\n",
        "            raise ValueError(\"dataset can be either 'nyu' or 'kitti' but got {}\".format(dataset))\n",
        "\n",
        "        model, _, _ = model_io.load_checkpoint(pretrained_path, model)\n",
        "        model.eval()\n",
        "        self.model = model.to(self.device)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def predict_pil(self, pil_image, visualized=False):\n",
        "        # pil_image = pil_image.resize((640, 480))\n",
        "        img = np.asarray(pil_image) / 255.\n",
        "\n",
        "        img = self.toTensor(img).unsqueeze(0).float().to(self.device)\n",
        "        pred = self.predict(img)\n",
        "        if visualized:\n",
        "            viz = utils.colorize(torch.from_numpy(pred).unsqueeze(0), vmin=None, vmax=None, cmap='magma')\n",
        "            # pred = np.asarray(pred*1000, dtype='uint16')\n",
        "            viz = Image.fromarray(viz)\n",
        "            return bin_centers, pred, viz\n",
        "        return pred\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def predict(self, image):\n",
        "        bins, pred = self.model(image)\n",
        "        pred = np.clip(pred.detach().cpu().numpy(), self.min_depth, self.max_depth)\n",
        "\n",
        "        # Flip\n",
        "        image = torch.Tensor(np.array(image.cpu().numpy())[..., ::-1].copy()).to(self.device)\n",
        "        pred_lr = self.model(image)[-1]\n",
        "        pred_lr = np.clip(pred_lr.detach().cpu().numpy()[..., ::-1], self.min_depth, self.max_depth)\n",
        "\n",
        "        # Take average of original and mirror\n",
        "        final = 0.5 * (pred + pred_lr)\n",
        "        final = nn.functional.interpolate(torch.Tensor(final), image.shape[-2:],\n",
        "                                          mode='bilinear', align_corners=True).cpu().numpy()\n",
        "\n",
        "        final[final < self.min_depth] = self.min_depth\n",
        "        final[final > self.max_depth] = self.max_depth\n",
        "        final[np.isinf(final)] = self.max_depth\n",
        "        final[np.isnan(final)] = self.min_depth\n",
        "\n",
        "        # centers = 0.5 * (bins[:, 1:] + bins[:, :-1])\n",
        "        # centers = centers.cpu().squeeze().numpy()\n",
        "        # centers = centers[centers > self.min_depth]\n",
        "        # centers = centers[centers < self.max_depth]\n",
        "\n",
        "        return final\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def predict_dir(self, test_dir, out_dir):\n",
        "        os.makedirs(out_dir, exist_ok=True)\n",
        "        transform = ToTensor()\n",
        "        all_files = glob.glob(os.path.join(test_dir, \"*\"))\n",
        "        self.model.eval()\n",
        "        for f in tqdm(all_files):\n",
        "            image = np.asarray(Image.open(f), dtype='float32') / 255.\n",
        "            image = transform(image).unsqueeze(0).to(self.device)\n",
        "\n",
        "            centers, final = self.predict(image)\n",
        "            # final = final.squeeze().cpu().numpy()\n",
        "\n",
        "            final = (final * self.saving_factor).astype('uint16')\n",
        "            basename = os.path.basename(f).split('.')[0]\n",
        "            save_path = os.path.join(out_dir, basename + \".png\")\n",
        "\n",
        "            Image.fromarray(final).save(save_path)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "  inferHelper = InferenceHelper()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/AdaBins\n",
            "Loading base model ()..."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done.\n",
            "Removing last two layers (global_pool & classifier).\n",
            "Building Encoder-Decoder model..Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGvI16WNsgaO",
        "outputId": "c1ba7b12-1a95-48d2-8664-901844077869"
      },
      "source": [
        "# setup network maskrcnn\n",
        "\n",
        "%cd /content/drive/MyDrive/Mask_RCNN/\n",
        "!python setup.py install"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Mask_RCNN\n",
            "WARNING:root:Fail load requirements file, so using default ones.\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:645: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
            "  % (opt, underscore_opt))\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:645: UserWarning: Usage of dash-separated 'license-file' will not be supported in future versions. Please use the underscore name 'license_file' instead\n",
            "  % (opt, underscore_opt))\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:645: UserWarning: Usage of dash-separated 'requirements-file' will not be supported in future versions. Please use the underscore name 'requirements_file' instead\n",
            "  % (opt, underscore_opt))\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing mask_rcnn.egg-info/PKG-INFO\n",
            "writing dependency_links to mask_rcnn.egg-info/dependency_links.txt\n",
            "writing top-level names to mask_rcnn.egg-info/top_level.txt\n",
            "warning: the 'license_file' option is deprecated, use 'license_files' instead\n",
            "adding license file 'LICENSE' (matched pattern 'LICENSE')\n",
            "reading manifest template 'MANIFEST.in'\n",
            "writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/__init__.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/utils.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/parallel_model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/config.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/visualize.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/utils.py to utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/parallel_model.py to parallel_model.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/config.py to config.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/model.py to model.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/visualize.py to visualize.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating 'dist/mask_rcnn-2.1-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing mask_rcnn-2.1-py3.7.egg\n",
            "Removing /usr/local/lib/python3.7/dist-packages/mask_rcnn-2.1-py3.7.egg\n",
            "Copying mask_rcnn-2.1-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "mask-rcnn 2.1 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/mask_rcnn-2.1-py3.7.egg\n",
            "Processing dependencies for mask-rcnn==2.1\n",
            "Finished processing dependencies for mask-rcnn==2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIYxe3OUslgn",
        "outputId": "e412350e-20c9-4a29-810e-534807768d24"
      },
      "source": [
        "# load rcnn model \n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import datetime\n",
        "import numpy as np\n",
        "import skimage.draw\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import datetime\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"/\")\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import model as modellib, utils\n",
        "from mrcnn.visualize import display_instances\n",
        "# Path to trained weights file\n",
        "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "\n",
        "# Directory to save logs and model checkpoints, if not provided\n",
        "# through the command line argument --logs\n",
        "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "############################################################\n",
        "#  Configurations\n",
        "############################################################\n",
        "\n",
        "\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import model as modellib, utils\n",
        "from mrcnn.visualize import display_instances\n",
        "\n",
        "# Directory to save logs and model checkpoints, if not provided\n",
        "# through the command line argument --logs\n",
        "logs= os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "class BalloonConfig(Config):\n",
        "    \"\"\"Configuration for training on the toy  dataset.\n",
        "    Derives from the base Config class and overrides some values.\n",
        "    \"\"\"\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"balloon\"\n",
        "\n",
        "    # We use a GPU with 12GB memory, which can fit two images.\n",
        "    # Adjust down if you use a smaller GPU.\n",
        "    IMAGES_PER_GPU = 2\n",
        "\n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 1  # Background + balloon\n",
        "\n",
        "    # Number of training steps per epoch\n",
        "    STEPS_PER_EPOCH = 100\n",
        "\n",
        "    # Skip detections with < 90% confidence\n",
        "    DETECTION_MIN_CONFIDENCE = 0.9\n",
        "\n",
        "\n",
        "############################################################\n",
        "#  Dataset\n",
        "############################################################\n",
        "\n",
        "class BalloonDataset(utils.Dataset):\n",
        "\n",
        "    def load_balloon(self, dataset_dir, subset):\n",
        "        \"\"\"Load a subset of the Balloon dataset.\n",
        "        dataset_dir: Root directory of the dataset.\n",
        "        subset: Subset to load: train or val\n",
        "        \"\"\"\n",
        "        # Add classes. We have only one class to add.\n",
        "        self.add_class(\"balloon\", 1, \"balloon\")\n",
        "\n",
        "        # Train or validation dataset?\n",
        "        assert subset in [\"train\", \"val\"]\n",
        "        dataset_dir = os.path.join(dataset_dir, subset)\n",
        "\n",
        "        # Load annotations\n",
        "        # VGG Image Annotator (up to version 1.6) saves each image in the form:\n",
        "        # { 'filename': '28503151_5b5b7ec140_b.jpg',\n",
        "        #   'regions': {\n",
        "        #       '0': {\n",
        "        #           'region_attributes': {},\n",
        "        #           'shape_attributes': {\n",
        "        #               'all_points_x': [...],\n",
        "        #               'all_points_y': [...],\n",
        "        #               'name': 'polygon'}},\n",
        "        #       ... more regions ...\n",
        "        #   },\n",
        "        #   'size': 100202\n",
        "        # }\n",
        "        # We mostly care about the x and y coordinates of each region\n",
        "        # Note: In VIA 2.0, regions was changed from a dict to a list.\n",
        "        annotations = json.load(open(os.path.join(dataset_dir, \"via_region_data.json\")))\n",
        "        annotations = list(annotations.values())  # don't need the dict keys\n",
        "\n",
        "        # The VIA tool saves images in the JSON even if they don't have any\n",
        "        # annotations. Skip unannotated images.\n",
        "        annotations = [a for a in annotations if a['regions']]\n",
        "\n",
        "        # Add images\n",
        "        for a in annotations:\n",
        "            # Get the x, y coordinaets of points of the polygons that make up\n",
        "            # the outline of each object instance. These are stores in the\n",
        "            # shape_attributes (see json format above)\n",
        "            # The if condition is needed to support VIA versions 1.x and 2.x.\n",
        "            if type(a['regions']) is dict:\n",
        "                polygons = [r['shape_attributes'] for r in a['regions'].values()]\n",
        "            else:\n",
        "                polygons = [r['shape_attributes'] for r in a['regions']] \n",
        "\n",
        "            # load_mask() needs the image size to convert polygons to masks.\n",
        "            # Unfortunately, VIA doesn't include it in JSON, so we must read\n",
        "            # the image. This is only managable since the dataset is tiny.\n",
        "            image_path = os.path.join(dataset_dir, a['filename'])\n",
        "            image = skimage.io.imread(image_path)\n",
        "            height, width = image.shape[:2]\n",
        "\n",
        "            self.add_image(\n",
        "                \"balloon\",\n",
        "                image_id=a['filename'],  # use file name as a unique image id\n",
        "                path=image_path,\n",
        "                width=width, height=height,\n",
        "                polygons=polygons)\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\"Generate instance masks for an image.\n",
        "       Returns:\n",
        "        masks: A bool array of shape [height, width, instance count] with\n",
        "            one mask per instance.\n",
        "        class_ids: a 1D array of class IDs of the instance masks.\n",
        "        \"\"\"\n",
        "        # If not a balloon dataset image, delegate to parent class.\n",
        "        image_info = self.image_info[image_id]\n",
        "        if image_info[\"source\"] != \"balloon\":\n",
        "            return super(self.__class__, self).load_mask(image_id)\n",
        "\n",
        "        # Convert polygons to a bitmap mask of shape\n",
        "        # [height, width, instance_count]\n",
        "        info = self.image_info[image_id]\n",
        "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
        "                        dtype=np.uint8)\n",
        "        for i, p in enumerate(info[\"polygons\"]):\n",
        "            # Get indexes of pixels inside the polygon and set them to 1\n",
        "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
        "            mask[rr, cc, i] = 1\n",
        "\n",
        "        # Return mask, and array of class IDs of each instance. Since we have\n",
        "        # one class ID only, we return an array of 1s\n",
        "        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n",
        "\n",
        "    def image_reference(self, image_id):\n",
        "        \"\"\"Return the path of the image.\"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"balloon\":\n",
        "            return info[\"path\"]\n",
        "        else:\n",
        "            super(self.__class__, self).image_reference(image_id)\n",
        "\n",
        "\n",
        "def train(model):\n",
        "    \"\"\"Train the model.\"\"\"\n",
        "    # Training dataset.\n",
        "    dataset_train = BalloonDataset()\n",
        "    dataset_train.load_balloon(args.dataset, \"train\")\n",
        "    dataset_train.prepare()\n",
        "\n",
        "    # Validation dataset\n",
        "    dataset_val = BalloonDataset()\n",
        "    dataset_val.load_balloon(args.dataset, \"val\")\n",
        "    dataset_val.prepare()\n",
        "\n",
        "    # *** This training schedule is an example. Update to your needs ***\n",
        "    # Since we're using a very small dataset, and starting from\n",
        "    # COCO trained weights, we don't need to train too long. Also,\n",
        "    # no need to train all layers, just the heads should do it.\n",
        "    print(\"Training network heads\")\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=config.LEARNING_RATE,\n",
        "                epochs=30,\n",
        "                layers='heads')\n",
        "\n",
        "\n",
        "def color_splash(image, mask):\n",
        "    \"\"\"Apply color splash effect.\n",
        "    image: RGB image [height, width, 3]\n",
        "    mask: instance segmentation mask [height, width, instance count]\n",
        "\n",
        "    Returns result image.\n",
        "    \"\"\"\n",
        "    # Make a grayscale copy of the image. The grayscale copy still\n",
        "    # has 3 RGB channels, though.\n",
        "    gray = skimage.color.gray2rgb(skimage.color.rgb2gray(image)) * 255\n",
        "    # Copy color pixels from the original color image where mask is set\n",
        "    if mask.shape[-1] > 0:\n",
        "        # We're treating all instances as one, so collapse the mask into one layer\n",
        "        mask = (np.sum(mask, -1, keepdims=True) >= 1)\n",
        "        splash = np.where(mask, image, gray).astype(np.uint8)\n",
        "    else:\n",
        "        splash = gray.astype(np.uint8)\n",
        "    return splash\n",
        "\n",
        "\n",
        "def detect_and_color_splash(model, image, video_path=None):\n",
        "    r = model.detect([image], verbose=1)[0]\n",
        "    return r\n",
        "    \n",
        "\n",
        "class InferenceConfig(BalloonConfig):\n",
        "  GPU_COUNT = 1\n",
        "  IMAGES_PER_GPU = 1\n",
        "\n",
        "config = InferenceConfig()\n",
        "config.display()\n",
        "\n",
        "model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=logs)\n",
        "weights_path = '/content/drive/MyDrive/Mask_RCNN/mask_rcnn_balloon.h5'\n",
        "model.load_weights(weights_path, by_name=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     1\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.9\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 1\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                14\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           balloon\n",
            "NUM_CLASSES                    2\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                100\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:442: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:58: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3543: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3386: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1768: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1154: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/Mask_RCNN/mrcnn/model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/Mask_RCNN/mrcnn/model.py:399: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/Mask_RCNN/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/Mask_RCNN/mrcnn/model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/Mask_RCNN/mrcnn/model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/Mask_RCNN/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zfM9jPiooWi"
      },
      "source": [
        "# process for photogrametry\n",
        "\n",
        "from math import radians, cos, sin\n",
        "def get_rot(pry):\n",
        "  a=radians(pry[2])\n",
        "  b=radians(pry[0])\n",
        "  g=radians(pry[1])\n",
        "  r1=[cos(a)*cos(b), (cos(a)*sin(b)*sin(g))-(sin(a)*cos(g)), (cos(a)*sin(b)*cos(g))+(sin(a)*sin(g))]\n",
        "  r2=[sin(a)*cos(b), (cos(a)*sin(b)*sin(g))+(cos(a)*cos(g)), (sin(a)*sin(b)*cos(g))-(cos(a)*sin(g))]\n",
        "  r3=[0-sin(b), cos(b)*sin(g), cos(b)*cos(g)]\n",
        "  return(np.asarray([r1, r2, r3]))                                                           \n",
        "\n",
        "def mat(pry, tran):\n",
        "  rot=get_rot(pry)\n",
        "  conv=np.asarray([[-1,0,0],\n",
        "                 [0,0,1],\n",
        "                 [0,1,0]])\n",
        "  tran=np.asarray([[1,0,0,-tran[0]],\n",
        "                   [0,1,0,-tran[1]],\n",
        "                   [0,0,1,-tran[2]]])\n",
        "  return((rot@tran),conv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGJ4j6BTZhtD",
        "outputId": "6fb8df10-7ae5-4610-cc80-5146f17aa25c"
      },
      "source": [
        "# read image for process\n",
        "\n",
        "import cv2\n",
        "import time\n",
        "from PIL import Image\n",
        "st=time.time()\n",
        "img=cv2.imread(\"/content/drive/MyDrive/img_7.jpg\")\n",
        "with torch.no_grad():\n",
        "  pred = inferHelper.predict_pil(img)\n",
        "img=np.asarray(img)\n",
        "r=detect_and_color_splash(model, img, video_path=None)\n",
        "print(time.time()-st)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing 1 images\n",
            "image                    shape: (640, 480, 3)         min:    4.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  150.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
            "11.622938394546509\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dv5zMubRZ1n5",
        "outputId": "c8662831-e599-49d9-ac82-2912af061603"
      },
      "source": [
        "# img[:,:,0][r['masks'][:,:,0]==False]=0\n",
        "# img[:,:,2][r['masks'][:,:,0]==False]=0\n",
        "pred[0,0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(640, 480)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "fk-RluNYc9qA",
        "outputId": "a3a5bbcf-ab55-4230-dadd-65f2f069da99"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(pred[0,0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0a16c48990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZUWCsSsp7gI"
      },
      "source": [
        "\n",
        "# test for single image\n",
        "\n",
        "intrin=np.asarray([[424.73486349, 0., 223.21701931],\n",
        "                  [ 0., 438.5143282, 324.4098755 ],\n",
        "                  [ 0.,   0., 1.]])\n",
        "# rot=np.asarray([[1,0,0], [0,1,0], [0,0,1]])\n",
        "# tran=[0,0,0]\n",
        "extrininv,conv=mat([0,0,0],[0,0,0])\n",
        "# extrin=np.asarray([[8.045017123222351074e-01, -2.037209272384643555e-01, 5.579200983047485352e-01, 5.043879098892212198e+00],\n",
        "                  #  [-5.914024114608764648e-01, -1.878403425216674805e-01, 7.841933369636535645e-01, 4.060233421325683878e+00],\n",
        "                  #  [-5.495670065283775330e-02, -9.608401656150817871e-01, -2.715989053249359131e-01, 2.012014386653900200e+00]])\n",
        "# h=np.linalg.inv(np.concatenate((intrin@extrin,[[0,0,0,1]])))[:3]\n",
        "\n",
        "if r['masks'].shape[-1] > 0:\n",
        "  a=np.zeros(r['masks'][:,:,0].shape)\n",
        "  a[r['masks'][:,:,0]]=255\n",
        "  y,x=np.where(a==255)\n",
        "  _=[1]*len(x)\n",
        "  j=np.asarray([x,y,_])\n",
        "  p=[pred.squeeze()[y,x]]*3\n",
        "  p=np.asarray(p)\n",
        "  c1=np.concatenate((conv@((np.linalg.inv(intrin)@j)*p),[_]))\n",
        "  c2=np.concatenate((extrininv,[[0,0,0,1]]))\n",
        "  c=c2@c1#(np.asarray([j[:,0]/26,j[:,1]/2.85,j[:,2]]).T@np.linalg.inv(intrin)-tran)@(np.linalg.inv(rot))\n",
        "  ck=np.mean(c,1)\n",
        "  i=np.mean(j,1).astype(np.int)[:2]\n",
        "print(time.time()-st)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsnJDnszwaIe"
      },
      "source": [
        "# setup webcam stream\n",
        "\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      // const div = document.createElement('div');\n",
        "      // const capture = document.createElement('button');\n",
        "      // capture.textContent = 'Capture';\n",
        "      // div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      // document.body.appendChild(div);\n",
        "      // div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      // div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "\n",
        "  # get photo data\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  # get OpenCV format image\n",
        "  img = js_to_image(data) \n",
        "  # grayscale img\n",
        "  # gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "  # print(gray.shape)\n",
        "  # get face bounding box coordinates using Haar Cascade\n",
        "  # faces = face_cascade.detectMultiScale(gray)\n",
        "  # draw face bounding box on image\n",
        "  # for (x,y,w,h) in faces:\n",
        "  #    img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "  # save image\n",
        "  #cv2.imwrite(filename, img)\n",
        "\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbtcX2FP9w0z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "623447c4-be66-4326-9c51-daef8b7ee8ca"
      },
      "source": [
        "# funcs to get stream\n",
        "\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "  \n",
        "from IPython.display import Image\n",
        "import time\n",
        "try:\n",
        "  filename = take_photo('photo.jpg')\n",
        "  print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))\n",
        "  \n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "\n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      // const div = document.createElement('div');\n",
              "      // const capture = document.createElement('button');\n",
              "      // capture.textContent = 'Capture';\n",
              "      // div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      // document.body.appendChild(div);\n",
              "      // div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      // div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "ReferenceError: capture is not defined\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wpkc-p2XM9cG",
        "outputId": "13c250b6-7380-402d-f2df-bcd20a690574"
      },
      "source": [
        "#live test\n",
        "\n",
        "video_stream()\n",
        "import numpy as np\n",
        "import cv2\n",
        "# label for video\n",
        "from PIL import Image\n",
        "\n",
        "import asyncio\n",
        "import random\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0 \n",
        "\n",
        "async def depth(img): \n",
        "  st=time.time()\n",
        "  pred = inferHelper.predict_pil(img) #depth\n",
        "  print(\"depth: \",time.time()-st)\n",
        "  return(pred)\n",
        "\n",
        "async def ball(img):\n",
        "  st=time.time()\n",
        "  r = detect_and_color_splash(model, img, video_path=None) #rcnn\n",
        "  print(\"ball: \", time.time()-st)\n",
        "  return(r)\n",
        "\n",
        "async def main(img):\n",
        "    ## define a future object    \n",
        "    st=time.time()\n",
        "    task=[asyncio.ensure_future(ball(img)), asyncio.ensure_future(depth(img))]\n",
        "    await asyncio.gather(*task)\n",
        "    ## Print the result of our future\n",
        "    print(\"main: \",time.time()-st)\n",
        "    return(task[0].result(),task[1].result())\n",
        "loop = asyncio.get_event_loop()\n",
        "\n",
        "while True:\n",
        "    st=time.time()\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "   \n",
        "    # convert JS response to OpenCV Image\n",
        "    img = js_to_image(js_reply[\"img\"])\n",
        "    ac=time.time()\n",
        "    print(ac-st)\n",
        "    \n",
        " \n",
        "    r, pred = loop.run_until_complete(main(img))\n",
        "   \n",
        "    \n",
        "    intrin=np.asarray([[424.73486349, 0., 223.21701931],\n",
        "                      [ 0., 438.5143282, 324.4098755 ],\n",
        "                      [ 0.,   0., 1.]])\n",
        "# rot=np.asarray([[1,0,0], [0,1,0], [0,0,1]])\n",
        "# tran=[0,0,0]\n",
        "    extrininv,conv=mat([0,0,0],[0,0,0])\n",
        "# extrin=np.asarray([[8.045017123222351074e-01, -2.037209272384643555e-01, 5.579200983047485352e-01, 5.043879098892212198e+00],\n",
        "                  #  [-5.914024114608764648e-01, -1.878403425216674805e-01, 7.841933369636535645e-01, 4.060233421325683878e+00],\n",
        "                  #  [-5.495670065283775330e-02, -9.608401656150817871e-01, -2.715989053249359131e-01, 2.012014386653900200e+00]])\n",
        "# h=np.linalg.inv(np.concatenate((intrin@extrin,[[0,0,0,1]])))[:3]\n",
        "\n",
        "    if r['masks'].shape[-1] > 0:\n",
        "      a=np.zeros(r['masks'][:,:,0].shape)\n",
        "      a[r['masks'][:,:,0]]=255\n",
        "      y,x=np.where(a==255)\n",
        "      _=[1]*len(x)\n",
        "      j=np.asarray([x,y,_])\n",
        "      p=[pred.squeeze()[y,x]]*3\n",
        "      p=np.asarray(p)\n",
        "      c1=np.concatenate((conv@((np.linalg.inv(intrin)@j)*p),[_]))\n",
        "      c2=np.concatenate((extrininv,[[0,0,0,1]]))\n",
        "      c=c2@c1#(np.asarray([j[:,0]/26,j[:,1]/2.85,j[:,2]]).T@np.linalg.inv(intrin)-tran)@(np.linalg.inv(rot))\n",
        "      ck=np.mean(c,1)\n",
        "      i=np.mean(j,1).astype(np.int)[:2]\n",
        "      print(time.time()-st, time.time()-ac, ck)\n",
        "    else:\n",
        "      print(time.time()-st, time.time()-ac, \"skipped\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "    \n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "    \n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "    \n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "    \n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "      \n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "           \n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "      \n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML = \n",
              "          '<span style=\"color: red; font-weight: bold;\">' +\n",
              "          'When finished, click here or on the video to stop this demo</span>';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "      \n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 640; //video.videoWidth;\n",
              "      captureCanvas.height = 480; //video.videoHeight;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "      \n",
              "      return stream;\n",
              "    }\n",
              "    async function stream_frame(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "      \n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "            \n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "      \n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "      \n",
              "      return {'create': preShow - preCreate, \n",
              "              'show': preCapture - preShow, \n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.325387716293335\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
            "ball:  10.835702896118164\n",
            "depth:  0.3789710998535156\n",
            "main:  11.215567588806152\n",
            "12.542030572891235 11.216643333435059 skipped\n",
            "1.1117196083068848\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
            "ball:  0.3785209655761719\n",
            "depth:  0.24327731132507324\n",
            "main:  0.6223502159118652\n",
            "1.7385718822479248 0.6268539428710938 [-0.78315028  1.35870949  0.39408691  1.        ]\n",
            "1.213937520980835\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
            "ball:  0.37267494201660156\n",
            "depth:  0.24348950386047363\n",
            "main:  0.6170811653137207\n",
            "1.8368678092956543 0.6229314804077148 [-0.82818416  1.30156273  0.34066533  1.        ]\n",
            "1.0367364883422852\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
            "ball:  0.37973880767822266\n",
            "depth:  0.24206089973449707\n",
            "main:  0.6225764751434326\n",
            "1.6651277542114258 0.6283919811248779 [-0.91652331  1.25492766  0.32688946  1.        ]\n",
            "1.4399173259735107\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
            "ball:  0.3737752437591553\n",
            "depth:  0.24390506744384766\n",
            "main:  0.6186122894287109\n",
            "2.066566228866577 0.6266500949859619 [-0.60145539  1.32222198  0.03201268  1.        ]\n",
            "1.0112881660461426\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
            "ball:  0.37694525718688965\n",
            "depth:  0.24747371673583984\n",
            "main:  0.6249816417694092\n",
            "1.643507480621338 0.6322202682495117 [-0.66715372  1.34762448  0.08890363  1.        ]\n",
            "1.1895191669464111\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
            "ball:  0.36852121353149414\n",
            "depth:  0.24144959449768066\n",
            "main:  0.6109275817871094\n",
            "1.8079726696014404 0.6184546947479248 [-0.67270209  1.31932388  0.0934547   1.        ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c9d9c7be5426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mjs_reply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_html\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mjs_reply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-927cc021e481>\u001b[0m in \u001b[0;36mvideo_frame\u001b[0;34m(label, bbox)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvideo_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stream_frame(\"{}\", \"{}\")'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vji7iSBReR1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3de734f7-3878-4ec4-8043-f9b6ccd2a03d"
      },
      "source": [
        "import multiprocessing as mp\n",
        "mp.cpu_count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xufH1GAk9QtS",
        "outputId": "a008864b-d98d-461c-9d25-b62d0ea69d21"
      },
      "source": [
        "\n",
        "\n",
        "async def myCoroutine1(future):\n",
        "    ## simulate some 'work'\n",
        "    print(\"started1\")\n",
        "    time.sleep(0.2)\n",
        "    ## set the result of our future object\n",
        "    return(\"My Coroutine-turned-future1 has completed\")\n",
        "\n",
        "async def myCoroutine2(future):\n",
        "    ## simulate some 'work'\n",
        "    print(\"started2\")\n",
        "    time.sleep(0.5)\n",
        "    ## set the result of our future object\n",
        "    return(\"My Coroutine-turned-future2 has completed\")\n",
        "\n",
        "\n",
        "async def main():\n",
        "    ## define a future object\n",
        "    st=time.time()\n",
        "    future=asyncio.Future()\n",
        "    task=[asyncio.ensure_future(myCoroutine1(future)), asyncio.ensure_future(myCoroutine2(future))]\n",
        "    await asyncio.gather(*task)\n",
        "    ## Print the result of our future\n",
        "    print(time.time()-st)\n",
        "    print(task[0].result(),task[1].result())\n",
        "    #print(future.result())\n",
        "\n",
        "## Spin up a quick and simple event loop\n",
        "## and run until completed\n",
        "loop = asyncio.get_event_loop()\n",
        "try:\n",
        "    loop.run_until_complete(main())\n",
        "finally:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "started1\n",
            "started2\n",
            "0.7018990516662598\n",
            "My Coroutine-turned-future1 has completed My Coroutine-turned-future2 has completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "sGb6TFzL-_2J",
        "outputId": "c5c81d28-3e83-456b-b21d-79e9dd5c96b0"
      },
      "source": [
        "future=asyncio.Future()\n",
        "myCoroutine1(future)\n",
        "myCoroutine2(future)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-24f82c356b77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmyCoroutine1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmyCoroutine2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'coroutine' object has no attribute 'result'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbncPHP7HEoX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}